// Databricks notebook source
display(dbutils.fs.ls("..."))

// COMMAND ----------

val path = "..."
val parquetDF = spark.read.parquet(path)
parquetDF.printSchema()

// COMMAND ----------

parquetDF.select("*").show()
parquetDF.select("*").count()

// COMMAND ----------

def createParquetEvents(number: String)(f: => Unit) {
  f
}

// COMMAND ----------

createParquetEvents("10") {
  //val sysTime = System.nanoTime
  //jsonDF.write.mode("append").json("{/"Username": "patient1", "Carbs": 55, "Bolus": 7.857142857142857, "Basal": 1.3, "Date": 1489003399, "Glucose": 120.0}")
  parquetDF.write.mode("append").parquet("...")
}

// COMMAND ----------

val path = "..."
val jsonDF = spark.read.json(path)
jsonDF.printSchema()

// COMMAND ----------

jsonDF.select("*").show()

// COMMAND ----------


